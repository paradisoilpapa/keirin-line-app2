# -*- coding: utf-8 -*-
import streamlit as st
import numpy as np
import pandas as pd
import re
import unicodedata

st.set_page_config(page_title="æ”¿æ˜¥ã•ã‚“EVãƒã‚§ãƒƒã‚¯ï¼ˆå°ã ã‘ï¼‰", layout="wide")

# ========= å®šæ•° =========
MARKS = ["", "â—", "ã€‡", "â–²", "â–³", "Ã—", "Î±", "Î²"]

# ã‚¨ã‚·ãƒ£ãƒ­ãƒƒãƒ†ã•ã‚“å®Ÿæ¸¬ã®å°åˆ¥ç‡ï¼ˆãã®ã¾ã¾â€œé‡ã¿â€ã¨ã—ã¦åˆ©ç”¨ã—ã€æ­£è¦åŒ–ã§ç¢ºç‡åŒ–ï¼‰
RANK_STATS = {
    "â—": {"p1": 0.200, "pTop2": 0.480, "pTop3": 0.610},
    "ã€‡": {"p1": 0.200, "pTop2": 0.390, "pTop3": 0.470},
    "â–²": {"p1": 0.100, "pTop2": 0.260, "pTop3": 0.430},
    "â–³": {"p1": 0.130, "pTop2": 0.240, "pTop3": 0.400},
    "Ã—": {"p1": 0.190, "pTop2": 0.240, "pTop3": 0.410},
    "Î±": {"p1": 0.133, "pTop2": 0.184, "pTop3": 0.347},
    "Î²": {"p1": 0.108, "pTop2": 0.269, "pTop3": 0.409},
}
FALLBACK = "Î±"

# æœŸå¾…å€¤ãƒ«ãƒ¼ãƒ«ï¼ˆãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼ã€Œå¿…è¦â—¯å€ä»¥ä¸Šã€è¡¨ç¤ºï¼‰
E_MIN, E_MAX = 0.10, 0.60

def _sort_key_by_numbers(name: str):
    return list(map(int, re.findall(r"\d+", str(name))))

# ========= ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šåŸºæœ¬è¨­å®š =========
st.sidebar.header("è¨­å®š")
n_cars = st.sidebar.selectbox("å‡ºèµ°æ•°", [5,6,7,8,9], index=2)
trials  = st.sidebar.slider("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è©¦è¡Œå›æ•°", 2000, 30000, 12000, 1000)
tau     = st.sidebar.slider("é †ä½æ¸©åº¦(æ•£ã‚‰ã—)", 0.5, 2.0, 1.0, 0.05,
                            help="1.0=æ¨™æº–ã€‚å°ã•ã„ã¨ç¡¬ã‚/å¤§ãã„ã¨è’ã‚Œæ°—å‘³ã€‚")
seed    = st.sidebar.number_input("ä¹±æ•°ã‚·ãƒ¼ãƒ‰", value=20250904, step=1)

st.title("æ”¿æ˜¥ã•ã‚“EVãƒã‚§ãƒƒã‚¯ï¼ˆå°ã ã‘ã§â€œå¿…è¦ã‚ªãƒƒã‚ºâ€è¡¨ç¤ºï¼‰")
st.caption("â—ã‹ã‚‰ã®å…¨é€šã‚Šï¼ˆãƒ¯ã‚¤ãƒ‰/äºŒè»Šè¤‡/ä¸‰é€£è¤‡/äºŒè»Šå˜ï¼‰ï¼‹ä¸‰é€£å˜ï¼ˆâ—â†’ç›¸æ‰‹â†’å…¨ï¼‰ã€‚è¶³åˆ‡ã‚Šãªã—ã§â€œå¿…è¦ã‚ªãƒƒã‚ºâ€ã‚’ä¸€è¦§åŒ–ã€‚")

# ========= å°å…¥åŠ› =========
st.subheader("å°å…¥åŠ›ï¼ˆâ—ã¯å¿…ãš1ã¤ï¼‰")
cols = st.columns(n_cars)
marks = {}
for i in range(n_cars):
    with cols[i]:
        car = i+1
        marks[car] = st.selectbox(f"{car}ç•ª", MARKS, index=0, key=f"mk_{car}")

# â—ãƒã‚§ãƒƒã‚¯
anchors = [c for c in range(1, n_cars+1) if marks.get(c,"")=="â—"]
if len(anchors)!=1:
    st.warning("â—ã‚’ã¡ã‚‡ã†ã©1ã¤é¸ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()
one = anchors[0]

# è¡¨ç¤ºç”¨ï¼šå°ã®æ¨ªä¸¦ã³
def marks_line(mdict):
    order = ["â—","ã€‡","â–²","â–³","Ã—","Î±","Î²"]
    rev = {}
    for c,m in mdict.items():
        if m:
            rev.setdefault(m, []).append(str(c))
    parts=[]
    for m in order:
        if m in rev:
            parts.append(f"{m}{'ãƒ»'.join(rev[m])}")
    return "ã€€".join(parts)

st.markdown("#### å°")
st.write(marks_line(marks))

# ========= å˜ä¸€é †ä½ç”Ÿæˆï¼ˆPLï¼‰ =========
# å°â†’â€œ1ç€å¼·ã•â€é‡ã¿ï¼ˆp1å€¤ï¼‰ã‚’èŠ¯ã«ã€æ¸©åº¦tauã§æ•£ã‚‰ã™
w1 = np.array([RANK_STATS.get(marks.get(i+1,"") or FALLBACK, RANK_STATS[FALLBACK])["p1"]
               for i in range(n_cars)], dtype=float)

# æ¸©åº¦ã‚¹ã‚±ãƒ¼ãƒ«ï¼ˆtau<1ã§ç¡¬ã‚ã€>1ã§è’ã‚Œï¼‰
w1 = np.power(np.maximum(w1, 1e-9), 1.0/tau)
w1 = w1 / w1.sum()

rng = np.random.default_rng(int(seed))

def sample_order_from_weights(weights: np.ndarray) -> list[int]:
    # Gumbel-Maxã§PLé †ä½ã‚µãƒ³ãƒ—ãƒ«
    g = -np.log(-np.log(np.clip(rng.random(len(weights)), 1e-12, 1-1e-12)))
    score = np.log(weights+1e-12) + g
    return (np.argsort(-score)+1).tolist()  # 1-indexed carç•ªå·

# ========= ã‚«ã‚¦ãƒ³ãƒˆå™¨ =========
others = [k for k in range(1,n_cars+1) if k!=one]
wide_counts = {k:0 for k in others}
qn_counts   = {k:0 for k in others}
ex_counts   = {k:0 for k in others}
tri_counts  = {}               # ä¸‰é€£è¤‡ï¼ˆâ—-a-bï¼‰ unordered
st3_counts  = {}               # ä¸‰é€£å˜ï¼ˆâ—->a->bï¼‰ ordered

# ä¸‰é€£è¤‡ã®å…¨é€šã‚Šï¼ˆâ—å›ºå®šã€a<bã§å…¨åˆ—æŒ™ï¼‰
tri_all = []
for i,a in enumerate(others):
    for b in others[i+1:]:
        t = tuple(sorted([one, a, b]))
        tri_all.append(t)
        tri_counts[t] = 0

# ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰å…¨é€šã‚Š
st3_all=[]
for a in others:
    for b in range(1,n_cars+1):
        if b in (one, a): continue
        st3_all.append((a,b))
        st3_counts[(a,b)] = 0

# ========= ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ =========
for _ in range(trials):
    order = sample_order_from_weights(w1)  # ä¾‹: [1,5,2,3,4,6,7]
    top3 = set(order[:3]); top2 = set(order[:2])

    # ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-kï¼‰ï¼šä¸¡è€…Top3
    if one in top3:
        for k in others:
            if k in top3: wide_counts[k] += 1

    # äºŒè»Šè¤‡ï¼ˆâ—-kï¼‰ï¼šä¸¡è€…Top2
    if one in top2:
        for k in others:
            if k in top2: qn_counts[k] += 1

    # äºŒè»Šå˜ï¼ˆâ—->kï¼‰
    if order[0]==one:
        k2 = order[1]
        if k2 in ex_counts: ex_counts[k2] += 1

    # ä¸‰é€£è¤‡ï¼ˆâ—-a-bï¼‰
    if one in top3:
        other2 = sorted(list(top3 - {one}))
        if len(other2)==2:
            t = tuple(sorted([one, other2[0], other2[1]]))
            if t in tri_counts:
                tri_counts[t] += 1

    # ä¸‰é€£å˜ï¼ˆâ—->a->bï¼‰
    if order[0]==one:
        a = order[1]; b = order[2]
        if (a,b) in st3_counts:
            st3_counts[(a,b)] += 1

def need_from_cnt(cnt: int) -> float | None:
    if cnt<=0: return None
    p = cnt/float(trials)
    return round(1.0/max(p,1e-12), 2)

# ========= è¡¨ï¼ˆå…¨é€šã‚Šãƒ»è¶³åˆ‡ã‚Šãªã—ï¼‰ =========
st.markdown("### å‡ºåŠ›ï¼ˆã‚³ãƒ”ãƒ¼ç”¨ï¼‰")

# ä¸‰é€£è¤‡ï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰â€¦ å…¨é€šã‚Š
rows=[]
for t in sorted(tri_all, key=lambda x: (x[0],x[1],x[2])):
    cnt = tri_counts.get(t,0)
    need = need_from_cnt(cnt)
    if need is None:
        rows.append({"è²·ã„ç›®": f"{t[0]}-{t[1]}-{t[2]}", "è²·ãˆã‚‹å¸¯": "â€”"})
    else:
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({"è²·ã„ç›®": f"{t[0]}-{t[1]}-{t[2]}", "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"})
tri_df = pd.DataFrame(rows)

# ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰â€¦ å…¨é€šã‚Šï¼ˆâ€œä»¥ä¸Šâ€è¡¨è¨˜ï¼‰
rows=[]
for k in sorted(others):
    cnt = wide_counts.get(k,0)
    need = need_from_cnt(cnt)
    rows.append({
        "è²·ã„ç›®": f"{one}-{k}",
        "å¿…è¦ï¼ˆ=1/pï¼‰": "â€”" if need is None else f"{need:.1f}å€ä»¥ä¸Šã§è²·ã„"
    })
wide_df = pd.DataFrame(rows)

# äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰â€¦ å…¨é€šã‚Š
rows=[]
for k in sorted(others):
    cnt = qn_counts.get(k,0)
    need = need_from_cnt(cnt)
    if need is None:
        rows.append({"è²·ã„ç›®": f"{one}-{k}", "è²·ãˆã‚‹å¸¯": "â€”"})
    else:
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({"è²·ã„ç›®": f"{one}-{k}", "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"})
qn_df = pd.DataFrame(rows)

# äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰â€¦ å…¨é€šã‚Š
rows=[]
for k in sorted(others):
    cnt = ex_counts.get(k,0)
    need = need_from_cnt(cnt)
    if need is None:
        rows.append({"è²·ã„ç›®": f"{one}->{k}", "è²·ãˆã‚‹å¸¯": "â€”"})
    else:
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({"è²·ã„ç›®": f"{one}->{k}", "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"})
ex_df = pd.DataFrame(rows)

# ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰â€¦ å…¨é€šã‚Š
rows=[]
for a,b in sorted(st3_all, key=lambda x: (x[0],x[1])):
    cnt = st3_counts.get((a,b),0)
    need = need_from_cnt(cnt)
    if need is None:
        rows.append({"è²·ã„ç›®": f"{one}->{a}->{b}", "è²·ãˆã‚‹å¸¯": "â€”"})
    else:
        low, high = need*(1.0+E_MIN), need*(1.0+E_MAX)
        rows.append({"è²·ã„ç›®": f"{one}->{a}->{b}", "è²·ãˆã‚‹å¸¯": f"{low:.1f}ã€œ{high:.1f}å€ãªã‚‰è²·ã„"})
st3_df = pd.DataFrame(rows)

# ===== è¡¨ç¤ºï¼ˆnoteè²¼ä»˜ã‘ã—ã‚„ã™ãã€ã‹ã¤è¦‹ã‚„ã™ãï¼‰ =====
st.markdown("#### ä¸‰é€£è¤‡ï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰â€»å…¨é€šã‚Šãƒ»è»Šç•ªé †")
st.dataframe(tri_df, use_container_width=True)

st.markdown("#### ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰â€»å…¨é€šã‚Šãƒ»è»Šç•ªé †ï¼ˆâ€»ãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼‰")
st.dataframe(wide_df, use_container_width=True)

st.markdown("#### äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰â€»å…¨é€šã‚Šãƒ»è»Šç•ªé †")
st.dataframe(qn_df, use_container_width=True)

st.markdown("#### äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰â€»å…¨é€šã‚Šãƒ»è»Šç•ªé †")
st.dataframe(ex_df, use_container_width=True)

st.markdown("#### ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰â€»å…¨é€šã‚Šãƒ»è»Šç•ªé †")
st.dataframe(st3_df, use_container_width=True)

# ===== ã‚³ãƒ”ãƒ¼ç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆnoteç”¨ãƒŸãƒ‹æ•´å½¢ï¼‰ =====
def lines_from_df(df: pd.DataFrame, key: str, suffix_key: str) -> list[str]:
    if df is None or len(df)==0: return []
    out=[]
    for _,r in df.iterrows():
        name = str(r.get(key,""))
        if suffix_key in r and isinstance(r[suffix_key], str) and r[suffix_key]!="":
            out.append(f"{name}ï¼š{r[suffix_key]}")
        else:
            out.append(f"{name}ï¼šâ€”")
    out.sort(key=lambda s: _sort_key_by_numbers(s))
    return out

txt = []
txt.append(marks_line(marks))
txt.append("")
txt.append("ä¸‰é€£è¤‡ï¼ˆâ—-[ç›¸æ‰‹]-å…¨ï¼‰")
txt += lines_from_df(tri_df, "è²·ã„ç›®", "è²·ãˆã‚‹å¸¯")
txt.append("")
txt.append("ãƒ¯ã‚¤ãƒ‰ï¼ˆâ—-å…¨ï¼‰")
txt += lines_from_df(wide_df, "è²·ã„ç›®", "å¿…è¦ï¼ˆ=1/pï¼‰")
txt.append("")
txt.append("äºŒè»Šè¤‡ï¼ˆâ—-å…¨ï¼‰")
txt += lines_from_df(qn_df, "è²·ã„ç›®", "è²·ãˆã‚‹å¸¯")
txt.append("")
txt.append("äºŒè»Šå˜ï¼ˆâ—â†’å…¨ï¼‰")
txt += lines_from_df(ex_df, "è²·ã„ç›®", "è²·ãˆã‚‹å¸¯")
txt.append("")
txt.append("ä¸‰é€£å˜ï¼ˆâ—â†’[ç›¸æ‰‹]â†’å…¨ï¼‰")
txt += lines_from_df(st3_df, "è²·ã„ç›®", "è²·ãˆã‚‹å¸¯")
txt.append("")
txt.append("ï¼ˆâ€»è¡¨ç¤ºã•ã‚ŒãŸæ•°å€¤ã¯ã€ŒæœŸå¾…å€¤æˆç«‹ã«å¿…è¦ãªã‚ªãƒƒã‚ºã®ä¸‹é™ã€ã§ã™ã€‚ã“ã‚Œä»¥ä¸‹ã§ã¯æœŸå¾…å€¤ä¸è¶³ã€"
           "ã“ã‚Œä»¥ä¸Šã§ã¯ã‚ªãƒƒã‚ºãŒé›¢ã‚Œã‚‹ã»ã©ã«çš„ä¸­ç‡ãƒãƒ©ãƒ³ã‚¹ãŒå´©ã‚Œã†ã‚‹ãŸã‚ãƒã‚¤ãƒªã‚¹ã‚¯ã§ã™ã€‚ãƒ¯ã‚¤ãƒ‰ã¯ä¸Šé™æ’¤å»ƒï¼â€œå¿…è¦â—¯å€ä»¥ä¸Šâ€ã€‚ï¼‰")

st.markdown("### ğŸ“‹ noteè²¼ã‚Šä»˜ã‘ç”¨")
st.text_area("ã“ã“ã‚’é¸æŠã—ã¦ã‚³ãƒ”ãƒ¼", "\n".join(txt), height=420)
